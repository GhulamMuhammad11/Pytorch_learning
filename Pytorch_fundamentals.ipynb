{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd49bf3-f898-41e5-8063-2e2e495643d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864f276-8da7-43d0-821e-af5f439f568d",
   "metadata": {},
   "source": [
    "# Creating Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a0e02a-b06b-4d48-9ec2-e7880a9e389e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7) # used to create a scalar\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089edd5b-d148-4c15-bb98-1013f23ef612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim # used to check the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fefe0798-f4e5-4f7b-8abf-9904fa8c3108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # to get the number within a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc4414-ce22-4520-9bc3-db9a992a7025",
   "metadata": {},
   "source": [
    "# Creating Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a21fd79c-06c6-40d6-85a8-6a27a09c4787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7]) #used to create a vector\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b15907-366b-4fd4-baa9-6d20bbc1e02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97f6535-922d-4db0-b967-0339b9137dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector.item()\n",
    "#This code is giving runtime error because item cannot convert any tensor that have more than one element. To do we have to use indexing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "398f6ecf-a7d5-4193-b06d-3fc08c83fdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3abb53e-f1ba-4541-901a-073dd2a2fb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape # this shape method is different from ndim. It tell us the number of dimensions inside a tensor while ndim tells the outer dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7effb0-036c-4d27-857c-5bbf32264bea",
   "metadata": {},
   "source": [
    "# Creating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "618b8eed-0133-4301-93b5-bc53953b3fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [5, 6, 7],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1,2,3],\n",
    "              [5,6,7],\n",
    "              [7,8,9]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91af4e9f-47a6-47e9-9142-e6667fd0e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "676a2fc5-5908-461a-8706-41847910839e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5983d4a-c97c-407e-9053-650caea73cc3",
   "metadata": {},
   "source": [
    "# Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cdcbec70-490e-44bf-b3a2-7ac31e0fa99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 2, 6]), 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensors = torch.rand(size = (2,3,2,6))\n",
    "rand_tensors.shape,rand_tensors.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee032242-0a7c-421d-a6a9-ba8f4eaa8250",
   "metadata": {},
   "source": [
    "# Zeros and ones Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64e20ddf-6b7c-44ad-bc39-6e6afdb969c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size = (3,4))\n",
    "zeros, zeros.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfe099d4-0fa0-4660-9eab-3d230ecb6e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size = (3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ab7b7ed-4c23-4500-b325-c902fa85fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range = torch.arange(0,10,2)\n",
    "range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b835142-a67d-4940-a87b-1d1654326479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you want to create a tensor of zeros or ones with the same shape, you can use\n",
    "zero_like = torch.zeros_like(input = range)\n",
    "zero_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4847462-36eb-4c0c-8f92-58fea608e2c6",
   "metadata": {},
   "source": [
    "# Tensor Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ff272a60-c58c-46f9-8721-7fcaac60532f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3.]), 1, torch.Size([2]), device(type='cpu'), torch.float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor = torch.tensor(data = [1.0,3],\n",
    "            dtype = None,\n",
    "            device = None,\n",
    "            requires_grad = False)\n",
    "float32_tensor, float32_tensor.ndim, float32_tensor.shape, float32_tensor.device, float32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bcf0e66b-4c1b-4515-abfc-4d9aecdb2882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], dtype=torch.float16),\n",
       " 1,\n",
       " torch.Size([3]),\n",
       " device(type='cpu'),\n",
       " torch.float16)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor = torch.tensor(data = [1,2,3],\n",
    "            dtype = torch.float16,\n",
    "            device = None,\n",
    "            requires_grad = False)\n",
    "float32_tensor, float32_tensor.ndim, float32_tensor.shape, float32_tensor.device, float32_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796bc33-de70-4c63-a033-8257fdad77a5",
   "metadata": {},
   "source": [
    "# Manipulating Tensors - Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "abb8212e-4084-4525-aaf4-42903d84f348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1183, 0.9437, 0.1024, 0.2358],\n",
       "          [0.6343, 0.3198, 0.0477, 0.9365],\n",
       "          [0.6179, 0.4088, 0.2416, 0.9439]]],\n",
       "\n",
       "\n",
       "        [[[0.2786, 0.8043, 0.6950, 0.4803],\n",
       "          [0.1325, 0.3460, 0.5688, 0.6646],\n",
       "          [0.6604, 0.9921, 0.0427, 0.1175]]]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand1 = torch.rand(size = (2,1,3,4))\n",
    "rand1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "49e1c8b8-2dcf-4154-8628-41ad6e44d560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.1183, 10.9437, 10.1024, 10.2358],\n",
       "          [10.6343, 10.3198, 10.0477, 10.9365],\n",
       "          [10.6179, 10.4088, 10.2416, 10.9439]]],\n",
       "\n",
       "\n",
       "        [[[10.2786, 10.8043, 10.6950, 10.4803],\n",
       "          [10.1325, 10.3460, 10.5688, 10.6646],\n",
       "          [10.6604, 10.9921, 10.0427, 10.1175]]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a4ffd3ec-a472-4392-82de-3e183b20c8f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-9.8817, -9.0563, -9.8976, -9.7642],\n",
       "          [-9.3657, -9.6802, -9.9523, -9.0635],\n",
       "          [-9.3821, -9.5912, -9.7584, -9.0561]]],\n",
       "\n",
       "\n",
       "        [[[-9.7214, -9.1957, -9.3050, -9.5197],\n",
       "          [-9.8675, -9.6540, -9.4312, -9.3354],\n",
       "          [-9.3396, -9.0079, -9.9573, -9.8825]]]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand1 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c506641-65f7-40b9-b0ed-8f9aa22a8e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.3656, 18.8748,  2.0485,  4.7152],\n",
       "          [12.6864,  6.3962,  0.9533, 18.7300],\n",
       "          [12.3586,  8.1764,  4.8320, 18.8777]]],\n",
       "\n",
       "\n",
       "        [[[ 5.5715, 16.0865, 13.8999,  9.6070],\n",
       "          [ 2.6509,  6.9198, 11.3764, 13.2914],\n",
       "          [13.2087, 19.8423,  0.8534,  2.3493]]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand1 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3c3296fa-29eb-4e1f-8bbb-413ecd0546b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.1828, 9.4374, 1.0242, 2.3576],\n",
       "          [6.3432, 3.1981, 0.4767, 9.3650],\n",
       "          [6.1793, 4.0882, 2.4160, 9.4389]]],\n",
       "\n",
       "\n",
       "        [[[2.7858, 8.0433, 6.9499, 4.8035],\n",
       "          [1.3254, 3.4599, 5.6882, 6.6457],\n",
       "          [6.6044, 9.9211, 0.4267, 1.1747]]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiply(rand1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f021ee01-aa1f-4799-9157-273bc5c12f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 3, 6])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(10,5,3,4)\n",
    "tensor2 = torch.randn(10,5,4,6)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "43eaf49e-f872-4a17-8d6f-ed67dac8aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some rules for the matrix multiplication. \n",
    "    #1. The inner dimensions must be same.\n",
    "    #2. The outer dimensions will be the ouput tensor shape.\n",
    "    #3. For the tensors having more than 2 dimensions, the batch sizes must match. For example, (10,2,4) , (10,4,5) : as the last dimension of tensor1 is \n",
    "        #4 and second-to-last dimension of second tensor is 4 so the output shape will be (2,5). Also, see that batch size is also same. \n",
    "    #4. If we have two tensors having same rows and column, but the batch size is missing in any one of the tensor, then it will add an additional dimension\n",
    "        #in the missing tensor and remove the output. Example is given in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "34cb8cf1-72fd-465c-84ba-f46cb8b3960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 4, 5])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(10, 3, 4,5)\n",
    "tensor2 = torch.randn(3,5, 5)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4998708f-558a-47b1-bc26-d8159b03a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are different ways to multiply tensors\n",
    "#tensor1*tensor2\n",
    "#tensor1@tensor2\n",
    "#torch.matmul(tensor1,tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25cd8ed-8083-471d-a454-0a963aa9ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(105)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "tens1 = torch.tensor([4,5,8])\n",
    "value = 0\n",
    "for i in range(len(tens1)):\n",
    "    value += tens1[i]*tens1[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609170e3-25fd-45d5-881b-f6b131b519af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(105)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tens3 = torch.matmul(tens1,tens1)\n",
    "tens3\n",
    "\n",
    "#it is recommended to use matmul because of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23dc4efb-5824-4bed-b79d-f58789e81a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we are getting a shape error, then we can simply transpose any matrix.\n",
    "tens2 = torch.tensor([[1,2,3,3],\n",
    "                     [1,2,3,4]])\n",
    "tens4 = torch.transpose(input = tens2,dim0 = 0,dim1 = 1)\n",
    "tens4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a328553-31a7-4179-a5c9-f6300631ba9a",
   "metadata": {},
   "source": [
    "# Getting a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e138745f-ce4a-49a1-b4c5-ee15bc4b89cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 24 14:37:34 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti    WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   35C    P8               11W / 160W|    652MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      3500    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7324    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      8812    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8972    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9112    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A      9412    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     10232    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10408    C+G   ...on\\128.0.2739.79\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12296    C+G   ...__8wekyb3d8bbwe\\Microsoft.Notes.exe    N/A      |\n",
      "|    0   N/A  N/A     12904    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     13764    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14068    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14372    C+G   ...m\\AppData\\Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
      "|    0   N/A  N/A     16324    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     16948    C+G   ...on\\128.0.2739.79\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     18204    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     18964    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     22840    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     25212    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "887886f9-2735-476a-8c33-acf3d6544198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6bfe157-f4ce-4649-9826-e65af3a9877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "727aa6bf-016c-42cc-b5eb-e3828826e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "878b289c-4d3f-4762-859e-4badb8d43234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fa0202d-3a5e-41d1-8023-1c45e7dbcbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02ef4eab-82ed-4a29-b3c0-85c6dcf8bca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3], dtype=int64), device(type='cpu'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get back on cpu\n",
    "tensor.cpu().numpy() , tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7261f-67e5-4afd-8e3f-41289405f2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
